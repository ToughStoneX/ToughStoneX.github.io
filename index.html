<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hongbin Xu</title>
    
    <meta name="author" content="Hongbin Xu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
        <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>

<table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
                <td style="padding:2.5%;width:60%;vertical-align:middle">
                    <p style="text-align:center">
                        <name>Hongbin Xu</name>
                    </p>
                    <p>
                        I am a second year PHD student in the Department of Automation in South China University of Technology (SCUT), advised by Prof. <a href="https://www.scholat.com/auwxkang"> Wenxiong Kang </a>                        
                    </p>
                    <p>
                        I am broadly interested in computer vision and deep learning. My current research focuses on:
                    </p><li style="margin: 5px;">
                        <b>3D reconstruction</b>: especially for <b>Multi-view Stereo (MVS)</b> (Explicit 3D reconstruction) and <b>Neural Radiance Field (NeRF)</b> (Implicit 3D reconstruction).
                    </li>
                    <li style="margin: 5px;">
                        <b>Self-supervised Learning</b>: especially for unsupervised/self-supervised approaches for tasks like depth estimation (monocula/stereo/multi-view).
                    </li>
                    <li style="margin: 5px;">
                        <b>3D Vision</b>: especially for 3D representation learning for vision applications such as 3D biometrics, point cloud perceptions, and etc.
                    </li>
                    <p></p>
                    <p style="text-align:center">
                        <a href="hongbinxu1013@gmail">Email</a> &nbsp;/&nbsp;
                        <a href="https://scholar.google.com/citations?user=mRC_emoAAAAJ&hl=zh-CN"> Google Scholar</a> &nbsp;/&nbsp;
                        <a href="https://github.com/ToughStoneX"> Github </a>
                    </p>
                </td>
                <td style="padding:2.5%;width:30%;max-width:30%">
                    <img style="width:50%;max-width:50%" alt="profile photo" src="assets/xhb.jpg">
                </td>
            </tr>
            </tbody></table>
    
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading>Experience</heading>
                    <p></p><li style="margin: 5px;">
                        <b>2020-2021:</b> Research Intern in Multimedia Laboratory (MMLAB) of Shenzhen Institutes of Advanced Technology (SIAT), University of Chinese Academy of Sciences (UCAS), advised by <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=zh-CN&oi=ao"> Prof. Yu Qiao </a>.
                    </li><p></p>
                    <p></p><li style="margin: 5px;">
                        <b>2021-2022:</b> Research Intern in Alibaba Damo Academy, advised by <a href="https://scholar.google.com/citations?user=Ot0PPAcAAAAJ&hl=zh-CN"> Zhipeng Zhou </a>.
                    </li><p></p>
                </td>
            </tr>
            </tbody></table>
    
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <p><heading>Preprint</heading></p>
                    <p>
                        * indicates equal contribution
                    </p>
                </td>
            </tr>
            </tbody></table>
    
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
            <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="assets/SEMVS_challenge.png" alt="dise">
                    <img style="width:100%;max-width:100%" src="assets/SEMVS.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle>Semi-supervised Deep Multi-view Stereo</papertitle>
                    <br>
                    <strong>Hongbin Xu</strong>, Zhipeng Zhou, Weitao Chen, Baigui Sun, Yang Liu, Hao Li, Wenxiong Kang
                    <br>
                    <br>
                    <a href="https://arxiv.org/abs/2207.11699">[Arxiv]</a>
                    [Code]
                    <a href=https://github.com/ToughStoneX/MVS_Evaluation_Benchmark>[Data/Benchmark]</a>
                    <br>
                    <p> We firstly explore a novel semi-supervised setting of learning-based MVS problem that only a tiny part of the MVS data is attached with dense depth ground truth.
                        The semi-supervised MVS (Semi-MVS) problem may break the basic assumption in semi-supervised learning that unlabeled data and labeled data share the same label space and data distribution.
                        To handle these issues, we propose a novel semi-supervised MVS framework, namely SE-MVS.
                        We evaluate our methods on existing benchmarks (DTU, Tanks&Temples) and self-built MVS 3D reconstruction benchmarks (BlendedMVS, GTASFM).
                    </p>
                </td>
            </tr>
    
    
    
            </tbody></table><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <p><heading>Publications</heading></p>
                    <p>
                        * indicates equal contribution
                    </p>
                </td>
            </tr>
            </tbody></table>
    
    
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    
            <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="assets/JDACS_motivation.png" alt="dise">
                    <img style="width:100%;max-width:100%" src="assets/JDACS.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle>Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation</papertitle>
                    <br>
                    <strong>Hongbin Xu</strong>*, Zhipeng Zhou*, Yu Qiao, Wenxiong Kang, Qiuxia Wu
    
                    <br>
                    <em>Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021, <strong><font color="red">Distinguished Paper Award</font></strong>
                    <br>
                    <a href="https://www.aaai.org/AAAI21Papers/AAAI-2549.XuH.pdf">[Paper]</a>
                    <a href="https://arxiv.org/abs/2104.05374">[Arxiv]</a>
                    <a href="https://github.com/ToughStoneX/Self-Supervised-MVS">[Code]</a>
                    <br>
                    <p> We propose a self-supervised/unsupervised framework for learning-based Multi-view Stereo (MVS).
                        To handle the color constancy ambiguity problem in previous self-supervised MVS methods, we propose a novel framework integrated with more reliable supervision guided by semantic co-segmentation and data-augmentation.
                        Experimental results show that our proposed method can achieve competetive performance compared with state-of-the-art fully-supervised MVS methods as well as the unsupervised methods.
                    </p>
                </td>
            </tr>
    
            <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="assets/UMVS_motivation.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle>Digging into Uncertainty in Self-supervised Multi-view Stereo</papertitle>
                    <br>
                    <strong>Hongbin Xu</strong>, Zhipeng Zhou, Yali Wang, Wenxiong Kang, Baigui Sun, Hao Li, Yu Qiao
    
                    <br>
                    <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
                    <br>
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_Digging_Into_Uncertainty_in_Self-Supervised_Multi-View_Stereo_ICCV_2021_paper.pdf">[Paper]</a>
                    <a href="https://arxiv.org/abs/2108.12966">[Arxiv]</a>
                    <a href="https://github.com/ToughStoneX/U-MVS">[Code]</a>
                    <br>
                    <p> We propose to estimate epistemic uncertainty in self-supervised MVS, accounting for what the model ignores.
                        Considering the two problems: ambiguious supervision in foreground and invalid supervision in background, we propose an uncertainty-guided self-supervised MVS framework, namely U-MVS.
                        Extensive experiments show that our U-MVS framework achieves the best performance among state-of-the-art unsupervised methods.
                    </p>
                </td>
            </tr>
    
    
            </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://jonbarron.info/">Website Template</a>
                        </p>
                    </td>
                    
                </tr>
            </tbody></table>

</tbody></table>

<center><p>
<div id="-widget" style="width:5%">
    <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=dx3QCLBztewbMfN76m1Up13jEsk5OusHR3-hnKOHG4s&cl=ffffff&w=a"></script> -->
    <!-- <a href="https://clustrmaps.com/site/1bsax"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=dx3QCLBztewbMfN76m1Up13jEsk5OusHR3-hnKOHG4s&cl=ffffff" /></a> -->
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=dx3QCLBztewbMfN76m1Up13jEsk5OusHR3-hnKOHG4s"></script>
</div>
<br>
&copy; Hongbin Xu | Last updated: Jan 7, 2023
</center></p>
</body>

</body>

</html>